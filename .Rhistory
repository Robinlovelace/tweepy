head(coord)
head(coords)
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
coords <- lapply(coords, function(x) if(is.null(x)) {x <- c(0,0) })
coords <- unlist(coords, recursive = T)
head(coords)
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
coords[[2]]
coords[[1]]
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
coords <- sapply(coords, function(x) if(is.null(x)) {x <- c(0,0) })
coords <- unlist(coords, recursive = T)
coords <- sapply(coords, as.numeric)
coords <- unlist(coords, recursive = T)
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
coords <- sapply(coords, as.numeric)
coords <- unlist(coords, recursive = T)
text <- sapply(tweets, function(x) x$text )
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
coords <- sapply(coords, function(x) if(is.null(x)) {x <- c(0,0) })
coords <- unlist(coords, recursive = T)
nuls <- sapply(input.list, function(x) is.null(x))
nuls <- sapply(coords, function(x) is.null(x))
head(nuls)
summary(nuls)
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x))
summary(nuls)
summary(coords[nuls])
coords[nuls] <- c(0, 0)
lapply(coords[nuls], function(x) x <- c(0, 0))
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0))
coords <- unlist(coords, recursive = T)
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x))
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0))
coords <- unlist(coords, recursive = T)
class(coords)
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0))
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
plot(created, coords[,1])
t.out <- data.frame(text, lat = coords[,1], lon = coords[,2], created)
sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome",
t.out$text)
summary(sel)
t.out[sel,]
sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t.out$text, ignore.case = T )
summary(sel)
t.out[sel,]
t_out <- data.frame(text, lat = coords[,1], lon = coords[,2], created)
write.csv(t_out[sel, ], "house_tweets.csv")
sel <- grep("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t.out$text, ignore.case = T )
library(rjson) # library used to load .json files
files <- list.files(path = "testload/", full.names=T)
for(i in files){
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=",")))
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- strptime(sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created)
sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t.out$text, ignore.case = T )
filenum <- paste0(which(files == i), ".csv")
write.csv(t_out[sel, ], "output.csv", append = T)
}
i <- files[1]
i
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=",")))
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- strptime(sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
created <- strptime(sapply(tweets, function(x) x$created_at))
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created)
sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t.out$text, ignore.case = T )
sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T )
which(files == i)
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], "output.csv", append = T)
??append
write.csv(t_out[sel, ], file = "output.csv", append = T)
write.csv(t_out[sel, ], file = "output.csv", append = T)
sel <- grepl("a", t_out$text, ignore.case = T )
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = "output.csv", append = T)
sel <- grepl("x", t_out$text, ignore.case = T )
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = "output.csv", append = T)
write.table(t_out[sel, ], sep=",", file = "output.csv", append = T)
write.table(t_out[sel, ], sep=",", file = "output.csv", append = T)
write.table(t_out[sel, ], sep=",", file = "output.csv", append = T)
write.table(t_out[sel, ], sep=",", file = "output.csv", append = T, )
write.csv(t_out[sel, ], sep=",", file = paste0("output",which(files == i),".csv"), append = T, )
write.csv(t_out[sel, ], file = paste0("output",which(files == i),".csv"))
read.csv("output1.csv")
library(rjson) # library used to load .json files
files <- list.files(path = "testload/", full.names=T)
for(i in files){
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, n=10), collapse=",")))
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T )
sel <- grepl("x", t_out$text, ignore.case = T )
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("output",which(files == i),".csv"))
}
library(rjson) # library used to load .json files
files <- list.files(path = "testload/", full.names=T)
for(i in files){
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, n=10), collapse=",")))
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T )
sel <- grepl("a", t_out$text, ignore.case = T )
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("output",which(files == i),".csv"))
}
library(microbenchmark)
install.packages("microbenchmark")
library(microbenchmark)
start_time <- system.time()
start_time <- Sys.time()
start_time
end_time <- Sys.time()
end_time <- Sys.time()
(time_taken <- end_time - start_time)
# BigLoad.R - for loading large amounts of twitter data into R
# Unzip the files saved by tweepy (see https://github.com/Robinlovelace/tweepy)
# Save to "unzipped" (e.g. with gunzip), load these files
library(microbenchmark)
library(rjson) # library used to load .json files
files <- list.files(path = "data/unzipped/", full.names=T)
# i <- files[1] # uncomment to load 1
start_time <- Sys.time()
for(i in files){
# tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, n=1000), collapse=","))) # test subset
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, 1000), collapse=","))) # full dataset
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
language <- sapply(tweets, function(x) x$lang )
n_followers <- sapply(tweets, function(x) x$lang )
user_created <- sapply(tweets, function(x) x$user$created_at)
n_tweets <- sapply(tweets, function(x) x$user$statuses_count)
n_followers <- sapply(tweets, function(x) x$user$followers_count)
n_following <- sapply(tweets, function(x) x$user$friends_count)
user_location <- sapply(tweets, function(x) x$user$location)
user_description <- sapply(tweets, function(x) x$user$description)
user_id <- sapply(tweets, function(x) x$user$id)
user_idstr <- sapply(tweets, function(x) x$user$id_str)
user_name <- sapply(tweets, function(x) x$user$name)
user_screen_name <- sapply(tweets, function(x) x$user$screen_name)
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created,
language, n_followers, user_created, n_tweets, n_followers, n_following,
user_location)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T ) # original selection
# sel <- grepl("a", t_out$text, ignore.case = T ) # test selection - replace "a" with anything
sel <- grepl("new house|#newhouse|old house|#oldhouse|new home|#newhome|old home|#oldhome|new flat|#newflat|old flat|#oldflat|moving house|#movinghouse|move house|#movehouse|moving home|#movinghome|move home|#movehome|packing to move|packing up everything|unpacking everything|removals van|#packingtomove|#packingupeverything|#unpackingeverything|#removalsvan|bought a house|house bought|moved house|house sold|#boughtahouse|#housebought|#movedhouse|#housesold|first rent|#firstrent|new gaff|new housing|new accommodation|new crib|new bungalow|new apartment|new semi detached|new semi-detached|new detached|new cottage|new digs|new dwelling|new residence|new pad|new homes|new home's|new houses|new house's|#newgaff|#newhousing|#newaccommodation|#newcrib|#newbungalow|#newapartment|#newsemidetached|#newdetached|#newcottage|#newdigs|#newdwelling|#newresidence|#newpad|#newhomes|#newhouses|old gaff|old housing|old accommodation|old crib|old bungalow|old apartment|old semi detached|old semi-detached|old detached|old cottage|old digs|old dwelling|old residence|old pad|old homes|old home's|old houses|old house's|#oldgaff|#oldhousing|#oldaccommodation|#oldcrib|#oldbungalow|#oldapartment|#oldsemidetached|#olddetached|#oldcottage|#olddigs|#olddwelling|#oldresidence|#oldpad|#oldhomes|#oldhouses", t_out$text, ignore.case = T)
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("data/output",which(files == i),".csv"))
}
end_time <- Sys.time()
(time_taken <- end_time - start_time)
# BigLoad.R - for loading large amounts of twitter data into R
# Unzip the files saved by tweepy (see https://github.com/Robinlovelace/tweepy)
# Save to "unzipped" (e.g. with gunzip), load these files
library(microbenchmark)
library(rjson) # library used to load .json files
files <- list.files(path = "data/unzipped/", full.names=T)
# i <- files[1] # uncomment to load 1
start_time <- Sys.time()
for(i in files){
# tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, n=1000), collapse=","))) # test subset
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
language <- sapply(tweets, function(x) x$lang )
n_followers <- sapply(tweets, function(x) x$lang )
user_created <- sapply(tweets, function(x) x$user$created_at)
n_tweets <- sapply(tweets, function(x) x$user$statuses_count)
n_followers <- sapply(tweets, function(x) x$user$followers_count)
n_following <- sapply(tweets, function(x) x$user$friends_count)
user_location <- sapply(tweets, function(x) x$user$location)
user_description <- sapply(tweets, function(x) x$user$description)
user_id <- sapply(tweets, function(x) x$user$id)
user_idstr <- sapply(tweets, function(x) x$user$id_str)
user_name <- sapply(tweets, function(x) x$user$name)
user_screen_name <- sapply(tweets, function(x) x$user$screen_name)
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created,
language, n_followers, user_created, n_tweets, n_followers, n_following,
user_location)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T ) # original selection
# sel <- grepl("a", t_out$text, ignore.case = T ) # test selection - replace "a" with anything
sel <- grepl("new house|#newhouse|old house|#oldhouse|new home|#newhome|old home|#oldhome|new flat|#newflat|old flat|#oldflat|moving house|#movinghouse|move house|#movehouse|moving home|#movinghome|move home|#movehome|packing to move|packing up everything|unpacking everything|removals van|#packingtomove|#packingupeverything|#unpackingeverything|#removalsvan|bought a house|house bought|moved house|house sold|#boughtahouse|#housebought|#movedhouse|#housesold|first rent|#firstrent|new gaff|new housing|new accommodation|new crib|new bungalow|new apartment|new semi detached|new semi-detached|new detached|new cottage|new digs|new dwelling|new residence|new pad|new homes|new home's|new houses|new house's|#newgaff|#newhousing|#newaccommodation|#newcrib|#newbungalow|#newapartment|#newsemidetached|#newdetached|#newcottage|#newdigs|#newdwelling|#newresidence|#newpad|#newhomes|#newhouses|old gaff|old housing|old accommodation|old crib|old bungalow|old apartment|old semi detached|old semi-detached|old detached|old cottage|old digs|old dwelling|old residence|old pad|old homes|old home's|old houses|old house's|#oldgaff|#oldhousing|#oldaccommodation|#oldcrib|#oldbungalow|#oldapartment|#oldsemidetached|#olddetached|#oldcottage|#olddigs|#olddwelling|#oldresidence|#oldpad|#oldhomes|#oldhouses", t_out$text, ignore.case = T)
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("data/output",which(files == i),".csv"))
}
end_time <- Sys.time()
(time_taken <- end_time - start_time)
memory.limit()
list.files(path = "data/unzipped/", full.names = T, pattern = "json")
x <- list.files(path = "data/unzipped/", full.names = T, pattern = "json")
i <- x[1]
mess <- paste0("split -l 10000 ", i, " ", i)
system(mess)
x <- list.files(path = "data/unzipped/", full.names = T, pattern = "json$")
x
x <- list.files(path = "data/unzipped/", full.names = T, pattern = "json$")
i <- x[1]
start_time <- Sys.time()
for(i in x){
mess <- paste0("split -l 10000 ", i, " ", i)
system(mess)
print(x)
}
(split_time <- Sys.time() - start_time)
system("mkdir data/chunked")
library(rjson) # library used to load .json files
files <- list.files(path = "data/chunked/", full.names=T)
i <- files[1] # uncomment to load 1
print(paste0(t_out$filenum / length(x) * 100), "% done")
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
language <- sapply(tweets, function(x) x$lang )
n_followers <- sapply(tweets, function(x) x$lang )
user_created <- sapply(tweets, function(x) x$user$created_at)
n_tweets <- sapply(tweets, function(x) x$user$statuses_count)
n_followers <- sapply(tweets, function(x) x$user$followers_count)
n_following <- sapply(tweets, function(x) x$user$friends_count)
user_location <- sapply(tweets, function(x) x$user$location)
user_description <- sapply(tweets, function(x) x$user$description)
user_id <- sapply(tweets, function(x) x$user$id)
user_idstr <- sapply(tweets, function(x) x$user$id_str)
user_name <- sapply(tweets, function(x) x$user$name)
user_screen_name <- sapply(tweets, function(x) x$user$screen_name)
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created,
language, n_followers, user_created, n_tweets, n_followers, n_following,
user_location)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T ) # original selection
# sel <- grepl("a", t_out$text, ignore.case = T ) # test selection - replace "a" with anything
sel <- grepl("new house|#newhouse|old house|#oldhouse|new home|#newhome|old home|#oldhome|new flat|#newflat|old flat|#oldflat|moving house|#movinghouse|move house|#movehouse|moving home|#movinghome|move home|#movehome|packing to move|packing up everything|unpacking everything|removals van|#packingtomove|#packingupeverything|#unpackingeverything|#removalsvan|bought a house|house bought|moved house|house sold|#boughtahouse|#housebought|#movedhouse|#housesold|first rent|#firstrent|new gaff|new housing|new accommodation|new crib|new bungalow|new apartment|new semi detached|new semi-detached|new detached|new cottage|new digs|new dwelling|new residence|new pad|new homes|new home's|new houses|new house's|#newgaff|#newhousing|#newaccommodation|#newcrib|#newbungalow|#newapartment|#newsemidetached|#newdetached|#newcottage|#newdigs|#newdwelling|#newresidence|#newpad|#newhomes|#newhouses|old gaff|old housing|old accommodation|old crib|old bungalow|old apartment|old semi detached|old semi-detached|old detached|old cottage|old digs|old dwelling|old residence|old pad|old homes|old home's|old houses|old house's|#oldgaff|#oldhousing|#oldaccommodation|#oldcrib|#oldbungalow|#oldapartment|#oldsemidetached|#olddetached|#oldcottage|#olddigs|#olddwelling|#oldresidence|#oldpad|#oldhomes|#oldhouses", t_out$text, ignore.case = T)
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("data/output",which(files == i),".csv"))
print(paste0(t_out$filenum / length(x) * 100), "% done")
t_out$filenum / length(x)
print(paste0(which(files == i) / length(x) * 100), "% done")
which(files == i) / length(x) * 100)
which(files == i)
print(paste0(which(files == i) / length(x) * 100, "% done"))
length(x)
print(paste0(which(files == i) / length(files) * 100, "% done"))
# Save to "unzipped" (e.g. with gunzip), load these files
library(rjson) # library used to load .json files
files <- list.files(path = "data/chunked/", full.names=T)
# i <- files[1] # uncomment to load 1
start_time <- Sys.time()
for(i in files){
# tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, n=1000), collapse=","))) # test subset
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
language <- sapply(tweets, function(x) x$lang )
n_followers <- sapply(tweets, function(x) x$lang )
user_created <- sapply(tweets, function(x) x$user$created_at)
n_tweets <- sapply(tweets, function(x) x$user$statuses_count)
n_followers <- sapply(tweets, function(x) x$user$followers_count)
n_following <- sapply(tweets, function(x) x$user$friends_count)
user_location <- sapply(tweets, function(x) x$user$location)
user_description <- sapply(tweets, function(x) x$user$description)
user_id <- sapply(tweets, function(x) x$user$id)
user_idstr <- sapply(tweets, function(x) x$user$id_str)
user_name <- sapply(tweets, function(x) x$user$name)
user_screen_name <- sapply(tweets, function(x) x$user$screen_name)
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created,
language, n_followers, user_created, n_tweets, n_followers, n_following,
user_location)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T ) # original selection
# sel <- grepl("a", t_out$text, ignore.case = T ) # test selection - replace "a" with anything
sel <- grepl("new house|#newhouse|old house|#oldhouse|new home|#newhome|old home|#oldhome|new flat|#newflat|old flat|#oldflat|moving house|#movinghouse|move house|#movehouse|moving home|#movinghome|move home|#movehome|packing to move|packing up everything|unpacking everything|removals van|#packingtomove|#packingupeverything|#unpackingeverything|#removalsvan|bought a house|house bought|moved house|house sold|#boughtahouse|#housebought|#movedhouse|#housesold|first rent|#firstrent|new gaff|new housing|new accommodation|new crib|new bungalow|new apartment|new semi detached|new semi-detached|new detached|new cottage|new digs|new dwelling|new residence|new pad|new homes|new home's|new houses|new house's|#newgaff|#newhousing|#newaccommodation|#newcrib|#newbungalow|#newapartment|#newsemidetached|#newdetached|#newcottage|#newdigs|#newdwelling|#newresidence|#newpad|#newhomes|#newhouses|old gaff|old housing|old accommodation|old crib|old bungalow|old apartment|old semi detached|old semi-detached|old detached|old cottage|old digs|old dwelling|old residence|old pad|old homes|old home's|old houses|old house's|#oldgaff|#oldhousing|#oldaccommodation|#oldcrib|#oldbungalow|#oldapartment|#oldsemidetached|#olddetached|#oldcottage|#olddigs|#olddwelling|#oldresidence|#oldpad|#oldhomes|#oldhouses", t_out$text, ignore.case = T)
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("data/output",which(files == i),".csv"))
print(paste0(which(files == i) / length(files) * 100, "% done"))
}
end_time <- Sys.time()
(time_taken <- end_time - start_time)
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
??Error
cat("ERROR :",conditionMessage(e), "\n")
paste0("Error " i)
paste0("Error ", i)
tryCatch({
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
}, error=function(e){paste0("Error ", i)})
which(files == i)
for(i in files[756:length(files)]){
tryCatch({
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
}, error=function(e){paste0("Error ", i)})
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
language <- sapply(tweets, function(x) x$lang )
n_followers <- sapply(tweets, function(x) x$lang )
user_created <- sapply(tweets, function(x) x$user$created_at)
n_tweets <- sapply(tweets, function(x) x$user$statuses_count)
n_followers <- sapply(tweets, function(x) x$user$followers_count)
n_following <- sapply(tweets, function(x) x$user$friends_count)
user_location <- sapply(tweets, function(x) x$user$location)
user_description <- sapply(tweets, function(x) x$user$description)
user_id <- sapply(tweets, function(x) x$user$id)
user_idstr <- sapply(tweets, function(x) x$user$id_str)
user_name <- sapply(tweets, function(x) x$user$name)
user_screen_name <- sapply(tweets, function(x) x$user$screen_name)
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created,
language, n_followers, user_created, n_tweets, n_followers, n_following,
user_location)
# sel <- grepl("new house|new flat|moving house|move house|moving home|move home|#newhouse|#newflat|#movinghouse|#movehouse|#movinghome|#movehome", t_out$text, ignore.case = T ) # original selection
# sel <- grepl("a", t_out$text, ignore.case = T ) # test selection - replace "a" with anything
sel <- grepl("new house|#newhouse|old house|#oldhouse|new home|#newhome|old home|#oldhome|new flat|#newflat|old flat|#oldflat|moving house|#movinghouse|move house|#movehouse|moving home|#movinghome|move home|#movehome|packing to move|packing up everything|unpacking everything|removals van|#packingtomove|#packingupeverything|#unpackingeverything|#removalsvan|bought a house|house bought|moved house|house sold|#boughtahouse|#housebought|#movedhouse|#housesold|first rent|#firstrent|new gaff|new housing|new accommodation|new crib|new bungalow|new apartment|new semi detached|new semi-detached|new detached|new cottage|new digs|new dwelling|new residence|new pad|new homes|new home's|new houses|new house's|#newgaff|#newhousing|#newaccommodation|#newcrib|#newbungalow|#newapartment|#newsemidetached|#newdetached|#newcottage|#newdigs|#newdwelling|#newresidence|#newpad|#newhomes|#newhouses|old gaff|old housing|old accommodation|old crib|old bungalow|old apartment|old semi detached|old semi-detached|old detached|old cottage|old digs|old dwelling|old residence|old pad|old homes|old home's|old houses|old house's|#oldgaff|#oldhousing|#oldaccommodation|#oldcrib|#oldbungalow|#oldapartment|#oldsemidetached|#olddetached|#oldcottage|#olddigs|#olddwelling|#oldresidence|#oldpad|#oldhomes|#oldhouses", t_out$text, ignore.case = T)
t_out$filenum <- which(files == i)
write.csv(t_out[sel, ], file = paste0("data/output",which(files == i),".csv"))
print(paste0(which(files == i) / length(files) * 100, "% done"))
}
end_time <- Sys.time()
(time_taken <- end_time - start_time)
outs <- list.files(path = "data/", pattern=".csv", full.names=T)
output <- read.csv(outs[1])
output
for(j in outs[-1]){
output <- rbind(output, read.csv(j))
}
which(outs == j)
for(j in outs[-1]){
tryCatch(
output <- rbind(output, read.csv(j)))
num <- which(outs == j)
}
?tryCatch
which(i == files)
which(i = file)
which(i == file)
which(i == files)
i
for(j in outs[-1]){
tryCatch({
output <- rbind(output, read.csv(j))
}, error=function(e){paste0("Error ", which(outs == j))})
num <- which(outs == j)
}
summary(output)
write.csv(output, "output.csv")
source("analysis/geosel.R")
source("analysis/geosel.R")
geoT[geosel, ]
geoT <- SpatialPointsDataFrame(coords= matrix(c(t_out$lon, t_out$lat), ncol=2), data=t_out)
geoT[geosel, ]
source("analysis/geosel.R")
geoT[geosel, ]
geosel <- gBuffer(pw, width = 50000) # create buffer
plot(geosel) # plot to test dimensions make sense
geosel <- spTransform(geosel, CRS("+init=epsg:4326"))
proj4string(geoT) <- CRS("+init=epsg:4326")
geoT[geosel, ]
geoT@data[geosel, ]
geoT[geosel, ]@data
nrow(t_out)
nlines <- 0
sel <- grepl("pennine way", t_out$text, ignore.case = T ) # test selection
geoT <- SpatialPointsDataFrame(coords= matrix(c(t_out$lon, t_out$lat), ncol=2), data=t_out)
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
source("analysis/geosel.R")
geoT <- SpatialPointsDataFrame(coords= matrix(c(t_out$lon, t_out$lat), ncol=2), data=t_out)
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
proj4string(geoT) <- CRS("+init=epsg:4326")
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
t_out$filenum <- which(files == i)
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
sel <- grepl("pennine way", t_out$text, ignore.case = T ) # test selection
geoT <- SpatialPointsDataFrame(coords= matrix(c(t_out$lon, t_out$lat), ncol=2), data=t_out)
proj4string(geoT) <- CRS("+init=epsg:4326")
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
t_sel
source("analysis/geosel.R")
sel <- grepl("pennine way", t_out$text, ignore.case = T ) # test selection
geoT <- SpatialPointsDataFrame(coords= matrix(c(t_out$lon, t_out$lat), ncol=2), data=t_out)
proj4string(geoT) <- CRS("+init=epsg:4326")
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
t_sel
# system("mkdir data/chunked") # copy chunked pieces into one directory
# source("analysis/geosel.R")
library(rgdal)
ogrListLayers("pennine.gpx")
pw <- readOGR("pennine.gpx", layer = "tracks")
pw <- spTransform(pw, CRS("+init=epsg:27700")) # transform CRS to OSGB
library(rgeos)
geosel <- gBuffer(pw, width = 5000) # create buffer
plot(geosel) # plot to test dimensions make sense
geosel <- spTransform(geosel, CRS("+init=epsg:4326"))
# Setup
library(rjson) # library used to load .json files
files <- list.files(path = "data/chunked/", full.names=T)
# i <- files[1] # uncomment to load 1
start_time <- Sys.time()
nlines <- 0
for(i in files){
# tweets <- fromJSON(sprintf("[%s]", paste(readLines(i, n=1000), collapse=","))) # test subset
tryCatch({
tweets <- fromJSON(sprintf("[%s]", paste(readLines(i), collapse=","))) # full dataset
}, error=function(e){paste0("Error ", which(i == files))})
coords <- sapply(tweets, function(x) x$coordinates$coordinates )
nuls <- sapply(coords, function(x) is.null(x)) # identify out the problematic NULL values
coords[nuls] <- lapply(coords[nuls], function(x) x <- c(0, 0)) # convert to zeros to keep with unlist
coords <- matrix(unlist(coords, recursive = T), ncol = 2, byrow = T)
text <- sapply(tweets, function(x) x$text )
created <- sapply(tweets, function(x) x$created_at)
created <- strptime(created, "%a %b %d %H:%M:%S +0000 %Y")
language <- sapply(tweets, function(x) x$lang )
n_followers <- sapply(tweets, function(x) x$lang )
user_created <- sapply(tweets, function(x) x$user$created_at)
n_tweets <- sapply(tweets, function(x) x$user$statuses_count)
n_followers <- sapply(tweets, function(x) x$user$followers_count)
n_following <- sapply(tweets, function(x) x$user$friends_count)
user_location <- sapply(tweets, function(x) x$user$location)
user_description <- sapply(tweets, function(x) x$user$description)
user_id <- sapply(tweets, function(x) x$user$id)
user_idstr <- sapply(tweets, function(x) x$user$id_str)
user_name <- sapply(tweets, function(x) x$user$name)
user_screen_name <- sapply(tweets, function(x) x$user$screen_name)
t_out <- data.frame(text, lat = coords[,2], lon = coords[,1], created,
language, n_followers, user_created, n_tweets, n_followers, n_following,
user_location)
### geo selection part
sel <- grepl("pennine way", t_out$text, ignore.case = T ) # test selection
geoT <- SpatialPointsDataFrame(coords= matrix(c(t_out$lon, t_out$lat), ncol=2), data=t_out)
proj4string(geoT) <- CRS("+init=epsg:4326")
t_sel <- rbind(geoT[geosel, ]@data, t_out[sel, ])
t_out$filenum <- which(files == i)
write.csv(t_sel, file = paste0("data/output",which(files == i),".csv"))
print(paste0(which(files == i) / length(files) * 100, "% done"))
nlines <- nlines + nrow(t_out)
}
end_time <- Sys.time()
(time_taken <- end_time - start_time)
outs <- list.files(path = "data/", pattern=".csv", full.names=T)
output <- read.csv(outs[1])
for(j in outs[-1]){
tryCatch({
output <- rbind(output, read.csv(j))
}, error=function(e){paste0("Error ", which(outs == j))})
num <- which(outs == j)
}
summary(output)
write.csv(output, "output-pennine.csv")
nrow(output)
outs <- list.files(path = "data/", pattern=".csv", full.names=T)
output <- read.csv(outs[1])
for(j in outs[-1]){
tryCatch({
output <- rbind(output, read.csv(j))
}, error=function(e){paste0("Error ", which(outs == j))})
num <- which(outs == j)
}
summary(output)
tweets <- fromJSON(sprintf("[%s]", paste(readLines("data/unzipped/t1402075195564.json"), collapse=",")))
library(rjson) # library used to load .json files
tweets <- fromJSON(sprintf("[%s]", paste(readLines("data/unzipped/t1402075195564.json"), collapse=",")))
